<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LLM-Debugger</title>
  <style>
    body {
      font-family: system-ui, sans-serif;
      background: #ffffff;
      color: #222;
      margin: 0;
      padding: 0;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 2rem;
      line-height: 1.6;
    }
    h1 {
      font-size: 2.4rem;
      text-align: center;
    }
    .subtitle {
      text-align: center;
      font-size: 1.2rem;
      margin-bottom: 1.5rem;
    }
    .btn {
      display: inline-block;
      background: #000;
      color: white;
      padding: 0.6rem 1.2rem;
      border-radius: 6px;
      text-decoration: none;
      margin: 1rem 0;
    }
    .center {
      text-align: center;
    }
    img {
      max-width: 100%;
      border: 1px solid #ccc;
      border-radius: 8px;
      margin: 2rem 0;
    }
    ul {
      padding-left: 1.5rem;
    }
    .features {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      margin-top: 1rem;
    }
    @media (max-width: 640px) {
      .features {
        grid-template-columns: 1fr;
      }
    }
    footer {
      text-align: center;
      margin-top: 3rem;
      font-size: 0.9rem;
      color: #888;
    }
    .install {
      font-family: monospace;
      background: #f4f4f4;
      padding: 0.5rem 1rem;
      border-radius: 5px;
      display: inline-block;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>🔍 LLM-Debugger</h1>
    <p class="subtitle">A local-first log viewer for LLM calls — inspect prompts, tool calls, and view the full conversation flow step by step.</p>
    <div class="center">
      <a class="btn" href="https://github.com/akhalsa/llm_debugger" target="_blank">🌐 View on GitHub</a>
      <p class="install">pip install llm-debugger</p>
    </div>

    <img src="demo.gif" alt="Demo of LLM-Debugger" />

    <h2>What is it?</h2>
    <p>
      <strong>LLM-Debugger</strong> is a local-first tool for inspecting OpenAI API calls (Anthropic coming soon!).
      It helps you debug conversations and agents by logging everything locally, automatically grouping related messages, and rendering them in a simple UI.
      <a href="https://github.com/akhalsa/llm_debugger" target="_blank">Check out the repository</a> for more details.
    </p>

    <h2>Features</h2>
    <div class="features">
      <ul>
        <li>🧠 Prompt & response diffs between turns</li>
        <li>📂 Logs stored locally as JSON</li>
        <li>⚡ One-line setup via client wrapper</li>
        <li>🔐 Fully offline — no server, no account</li>
      </ul>
      <ul>
        <li>🔍 Automatic conversation tagging</li>
        <li>⏱️ Metadata + latency tracking</li>
        <li>🖥️ Simple, static UI served locally</li>
        <li>🧩 Works with any Python codebase</li>
      </ul>
    </div>

    <h2>Why use this?</h2>
    <p>
      Most LLM dev tools are hosted or heavyweight. <strong>llm-debugger</strong> gives you a fast, lightweight
      way to understand what your model is doing — no cloud needed.
    </p>

    <h2>Get Started</h2>
    <p>Install the package:</p>
    <pre><code>pip install llm-debugger</code></pre>

    <p>Then launch the viewer:</p>
    <pre><code>llm_logger</code></pre>
    <p>Or embed the UI in your app using FastAPI or Flask.</p>

    <div class="center">
      <p>🧪 Want to shape v2? <a href="https://github.com/akhalsa/llm_debugger/discussions" target="_blank">Join the discussion on GitHub</a></p>
      <a class="btn" href="https://github.com/akhalsa/llm_debugger" target="_blank">🌐 View the Project on GitHub</a>
    </div>

    <footer>
      Built by <a href="https://github.com/akhalsa" target="_blank">@akhalsa</a> • MIT Licensed
    </footer>
  </div>
</body>
</html>
